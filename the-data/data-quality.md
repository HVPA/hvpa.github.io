Data Quality
Maintaining data accuracy—defined as ensuring the data within the repository is described correctly (e.g variants are named according to the Human Genome Variation Society nomenclature system, data is internally consistent, etc.—is achieved via automated means at the time of submission.

Data accuracy checks are incorporated into the HVPA Exporter tool and issues are flagged to users before submission takes place. At the repository side, the HVPA Importer tool maps incoming data elements to common reference sequences to ensure internal consistency of naming.

Diagnostic Data
For data submitted by diagnostic laboratories (diagnostic data), we assume that the incoming data is of high quality—which we define as data that has been generated in a manner free from errors such as sequencing artefacts, incorrect calling bases and variants, etc.—due to the regulatory requirements that diagnostic laboratories must meet when generating this data. We purposely collect data from diagnostic labs only after they have reported results to the requesting clinician to ensure we capture the data past the point where changes can be made. If a laboratory subsequently finds that they have made an error in their report, a new report will be issued to the clinician and this new information will subsequently be submitted to the Node during the next data upload phase.

Research Data
Data contributed by laboratories that are not accredited for diagnostic purposes to the Node (research data) undergoes the same accuracy checks as diagnostic data regardless of whether they are submitted through the HVP Exporter or via a bulk, manual upload process. In terms of ensuring data quality, due to the disparate nature of the ways that research data can be generated, assessing data quality in a standardised fashion is difficult.

There are currently no recognised standards for accrediting research data generation practices that can be leveraged to assess the quality of data submitted to the Node. To address this, the Node is working to generate a national data quality standard. Until such time that a standard exists, the Node will continue to clearly differentiate the sources of data contained in the Node to allow users to clearly identify data that has been quality assessed to a recognised standard.

National Data Quality Standard
The Australian Node is a partner, alongside the Royal College of Pathologists of Australasia (RCPA) and the Human Variome Project International Coordinating Office, in a Federal Quality Use of Pathology Programme grant to develop a national standard for genetic data quality.

This project, will develop Australian standards to accredit DNA sequence variation databases to ensure that the data in the data bases are accurate and of sufficient quality so as they can be placed in the Australian Node repository and subsequently used by diagnostic laboratories to analyse and interpret genetic variants. The process will be based on the National Pathology Accreditation Advisory Council approach to standards development and will hopefully be accepted by NPAAC to enable accreditation via the National Association of Testing Authorities (NATA)/RCPA process. Longer term these standards will be fed into the Human Variome Project's standards development process to contribute to the development of international standards.